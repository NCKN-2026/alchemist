import os
import json
import pandas as pd
import numpy as np
from tqdm import tqdm
from collections import Counter
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report

# Import VLM c·ªßa ch√∫ng ta
from auto_lf.extractors.vlm_wrapper import VLMExtractor
from auto_lf.router import Router

# ================= C·∫§U H√åNH =================
DEV_JSON_PATH = "data/devset/dev.json"  # File ch·ª©a ·∫£nh v√† nh√£n dev
# ============================================

def main():
    if not os.path.exists(DEV_JSON_PATH):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y {DEV_JSON_PATH}")
        return

    print(f"--- 1. LOADING DATA ---")
    with open(DEV_JSON_PATH, "r") as f:
        dev_data = json.load(f)

    # Load Model (Ch·ªâ c·∫ßn CPU l√† ƒë·ªß cho vi·ªác test nhanh n√†y)
    vlm = VLMExtractor(device='cpu') 
    
    texts = []
    labels = []
    
    print(f"--- 2. EXTRACTING & MAPPING ---")
    # Qu√©t qua d·ªØ li·ªáu ƒë·ªÉ l·∫•y m√¥ t·∫£
    for item in tqdm(dev_data, desc="Analyzing"):
        img_path = item["path"]
        label = item["label"]
        
        if not os.path.exists(img_path):
             if os.path.exists(os.path.join(".", img_path)): img_path = os.path.join(".", img_path)
             else: continue

        try:
            # L·∫•y features (list c√°c t·ª´)
            feats_list = vlm.extract(img_path)
            # N·ªëi l·∫°i th√†nh 1 c√¢u ƒë·ªÉ d·ªÖ ph√¢n t√≠ch th·ªëng k√™
            text_desc = " ".join(feats_list)
            
            texts.append(text_desc)
            labels.append(label)
        except Exception as e:
            continue

    if len(texts) == 0:
        print("‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c d·ªØ li·ªáu n√†o.")
        return

    # Chuy·ªÉn sang DataFrame ƒë·ªÉ d·ªÖ x·ª≠ l√Ω
    df = pd.DataFrame({'text': texts, 'label': labels})
    
    print("\n" + "="*40)
    print("üìä PH√ÇN T√çCH T·ª™ KH√ìA (TOP KEYWORDS)")
    print("="*40)
    
    # In ra top 10 t·ª´ kh√≥a ƒë·∫∑c tr∆∞ng cho m·ªói class
    unique_labels = sorted(df['label'].unique())
    vectorizer = CountVectorizer(stop_words='english')
    
    for lbl in unique_labels:
        subset = df[df['label'] == lbl]['text']
        if len(subset) == 0: continue
        
        # ƒê·∫øm t·ª´
        all_words = " ".join(subset).split()
        counter = Counter(all_words)
        top_10 = counter.most_common(10)
        
        print(f"\nüè∑Ô∏è  LABEL {lbl} (T·ªïng {len(subset)} ·∫£nh):")
        print(f"   Top words: {', '.join([f'{w}({c})' for w, c in top_10])}")

    print("\n" + "="*40)
    print("üß† DIAGNOSTIC TRAINING (TRAIN TH·ª¨)")
    print("="*40)
    print("ƒêang train m·ªôt model Logistic Regression ƒë∆°n gi·∫£n tr√™n m√¥ t·∫£...")
    
    # Vector h√≥a d·∫°ng Bag-of-Words
    X = vectorizer.fit_transform(df['text'])
    y = df['label']
    
    # Train model
    clf = LogisticRegression(max_iter=1000, class_weight='balanced')
    clf.fit(X, y)
    
    # ƒê√°nh gi√° ƒë·ªô kh·ªõp (Accuracy tr√™n ch√≠nh t·∫≠p train)
    # N·∫øu Acc cao -> M√¥ t·∫£ kh·ªõp t·ªët v·ªõi nh√£n
    # N·∫øu Acc th·∫•p -> BLIP "nh√¨n g√† h√≥a cu·ªëc" ho·∫∑c d·ªØ li·ªáu qu√° kh√≥
    acc = clf.score(X, y)
    print(f"\n‚úÖ Mapping Accuracy (Training Score): {acc:.4f} ({acc*100:.2f}%)")
    
    if acc < 0.6:
        print("‚ö†Ô∏è C·∫¢NH B√ÅO: ƒê·ªô kh·ªõp th·∫•p! C√≥ th·ªÉ m√¥ t·∫£ c·ªßa BLIP kh√¥ng ch·ª©a th√¥ng tin ph√¢n lo·∫°i.")
    else:
        print("üöÄ T·ªêT: M√¥ t·∫£ vƒÉn b·∫£n ch·ª©a ƒë·ªß th√¥ng tin ƒë·ªÉ ph√¢n bi·ªát c√°c nh√£n.")

    # In feature importance (T·ª´ n√†o quan tr·ªçng nh·∫•t v·ªõi model)
    if len(unique_labels) == 2: # Ch·ªâ in n·∫øu l√† b√†i to√°n nh·ªã ph√¢n cho g·ªçn
        print("\nüîç T·ª™ KH√ìA QUY·∫æT ƒê·ªäNH (Feature Importance):")
        feature_names = vectorizer.get_feature_names_out()
        coefs = clf.coef_[0]
        sorted_idx = np.argsort(coefs)
        
        print(f"   Top words cho Label {unique_labels[0]} (Negative coefs):")
        top_neg = sorted_idx[:10]
        print(f"   -> {', '.join([feature_names[i] for i in top_neg])}")
        
        print(f"\n   Top words cho Label {unique_labels[1]} (Positive coefs):")
        top_pos = sorted_idx[-10:]
        print(f"   -> {', '.join([feature_names[i] for i in top_pos])}")

if __name__ == "__main__":
    main()